{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import seaborn as sns\n",
    "import pickle, gzip\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from sklearn.cluster import KMeans\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_python2():\n",
    "    with gzip.open('mnist.pkl.gz', 'rb') as fd:\n",
    "        #u = pickle._Unpickler(fd)\n",
    "        #u.encoding = 'latin1'\n",
    "        train_set, valid_set, test_set = pickle.load(fd)\n",
    "        #u.load()\n",
    "        return train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_python3():\n",
    "    with gzip.open('mnist.pkl.gz', 'rb') as fd:\n",
    "        u = pickle._Unpickler(fd)\n",
    "        u.encoding = 'latin1'\n",
    "        train_set, valid_set, test_set = u.load()\n",
    "        return train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(sys.version[0]=='3'):\n",
    "    train_set, valid_set, test_set = get_data_python3()\n",
    "elif(sys.version[0]=='2'):\n",
    "    train_set, valid_set, test_set = get_data_python2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train and val\n",
    "train_set = (np.concatenate([train_set[0], valid_set[0]], axis=0), \n",
    "                np.concatenate([train_set[1], valid_set[1]], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 60000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training set:\", len(train_set[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of each training set item (28x28 image 1-d array):  784\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of each training set item (28x28 image 1-d array): \", len(train_set[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshaping each 784 1-d array into 28x28 2-d array\n",
    "train_set[0].reshape(60000,28,28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating 4x4 grid of 10x10 patches\n",
    "def patch_creation(image):\n",
    "    patches = []\n",
    "    x=[0,6,12,18]\n",
    "    y=[0,6,12,18]\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            patch = image[i:i+10,j:j+10].reshape(-1,100)\n",
    "            patches.append(patch)\n",
    "    return(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(test): \n",
    "    fig = plt.figure(figsize=(4., 4.))\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes in inch.\n",
    "                     )\n",
    "\n",
    "    for ax, im in zip(grid, [test[0].reshape(10, 10), test[1].reshape(10, 10), test[2].reshape(10, 10), test[3].reshape(10, 10),\n",
    "                            test[4].reshape(10, 10), test[5].reshape(10, 10), test[6].reshape(10, 10), test[7].reshape(10, 10),\n",
    "                            test[8].reshape(10, 10), test[9].reshape(10, 10),test[10].reshape(10, 10),test[11].reshape(10, 10),\n",
    "                            test[12].reshape(10, 10), test[13].reshape(10, 10),test[14].reshape(10, 10),test[15].reshape(10, 10)]):\n",
    "        # Iterating over the grid returns the Axes.\n",
    "        ax.imshow(im, cmap='Greys_r')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is simply here to make sure that our grid creation works correctly\n",
    "def test_image():\n",
    "    #fetch one image\n",
    "    image = train_set[0][1].reshape(28,28)\n",
    "    \n",
    "    print(\"Image shape: \",image.shape)\n",
    "    \n",
    "    #create 16 - 10x10 patches\n",
    "    test = patch_creation(image)\n",
    "    \n",
    "    print(\"Num patches: \", len(test))\n",
    "    \n",
    "    #plotting the test image to see create patches\n",
    "    plot_image(test)\n",
    "    \n",
    "    #plt.imshow(image.reshape(28, 28), cmap='Greys_r')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (28, 28)\n",
      "Num patches:  16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 32 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping each 784 1-d array into 28x28 2-d array and creating patches for each image\n",
    "training_patches=[]\n",
    "for i in range(60000):\n",
    "    image = train_set[0][i].reshape(28,28)\n",
    "    training_patches.append(patch_creation(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of training images:  60000\n"
     ]
    }
   ],
   "source": [
    "print(\"Amount of training images: \", len(training_patches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of matrices (patches) in each training image:  16\n"
     ]
    }
   ],
   "source": [
    "print(\"Amount of matrices (patches) in each training image: \", len(training_patches[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing 1 patch from the 16 previously created for each image at random and appending to \n",
    "#training list\n",
    "train_cluster=[]\n",
    "for i in range(60000):\n",
    "    n = random.randint(0, 15)\n",
    "    train_cluster.append(training_patches[i][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a list of 6000 numbers where each is between 0 - 59999\n",
    "indices = random.sample(range(60000), 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending randomly sampled patches using the previously created list of indices\n",
    "train_cluster_sample=[]\n",
    "for ind in indices:\n",
    "    train_cluster_sample.append(train_cluster[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of our randomly sampled patches:  6000\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of our randomly sampled patches: \", len(train_cluster_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a 6000x100 matrix of zeros that where each row will be one of our samples\n",
    "training_matrix = np.zeros((6000,100))\n",
    "for i in range(6000):\n",
    "    #making eacch row a random patch\n",
    "    training_matrix[i,:] = train_cluster_sample[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create kmeans object\n",
    "kmeans = KMeans(n_clusters=50)\n",
    "# fit kmeans object to data\n",
    "kmeans.fit(training_matrix)\n",
    "# save new clusters for chart\n",
    "y_km = kmeans.predict(training_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_matrix_60k = np.zeros((60000,100))\n",
    "for i in range(60000):\n",
    "    training_matrix_60k[i,:] = train_cluster[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_km_60k = kmeans.predict(training_matrix_60k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster_dict=[]\n",
    "cluster_dict = {}\n",
    "for i in range(50):\n",
    "    key = str(i)\n",
    "    subtrain_matrix = training_matrix_60k[y_km_60k==i,:]\n",
    "    kmeans_sub = KMeans(n_clusters=50)\n",
    "    kmeans_sub.fit(subtrain_matrix)\n",
    "    cluster_dict[key] = kmeans_sub \n",
    "    y_km_sub = kmeans_sub.predict(subtrain_matrix)\n",
    "    #cluster_dict.append(y_km_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_with(vector, pad_width, iaxis, kwargs):\n",
    "    pad_value = kwargs.get('padder', 0)\n",
    "    vector[:pad_width[0]] = pad_value\n",
    "    vector[-pad_width[1]:] = pad_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_b(image):\n",
    "    patches16 = []\n",
    "    x_ = [0, 1, 2]\n",
    "    y_ = [0, 1, 2]\n",
    "    x=[0,6,12,18]\n",
    "    y=[0,6,12,18]\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            patches9 = []\n",
    "            for k in x_:\n",
    "                for l in y_:\n",
    "                    patch = image[i+k:i+k+10, j+l:j+l+10].reshape(-1,100)\n",
    "                    patches9.append(patch)\n",
    "            patches16.append(patches9)\n",
    "    return patches16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_patches = []\n",
    "for i in range(10000):\n",
    "    testing_reshaped = test_set[0][i].reshape(28,28)\n",
    "    testing_padded = np.pad(testing_reshaped, 1, pad_with)\n",
    "    testing_patched = patch_b(testing_padded)\n",
    "    testing_patches.append(testing_patched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded image:  (30, 30)\n",
      "Number of original patches:  16\n",
      "Number of recentered patches per original patch:  9\n",
      "Total number of patches for each image:  144\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of padded image: \", testing_padded.shape)\n",
    "print(\"Number of original patches: \", len(testing_patched))\n",
    "print(\"Number of recentered patches per original patch: \", len(testing_patched[0]))\n",
    "print(\"Total number of patches for each image: \", len(testing_patched) * len(testing_patched[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_patches = []\n",
    "random_indices = random.sample(range(60000), 6000)\n",
    "for i in random_indices:\n",
    "    training_reshaped = train_set[0][i].reshape(28,28)\n",
    "    training_padded = np.pad(training_reshaped, 1, pad_with)\n",
    "    training_patched = patch_b(training_padded)\n",
    "    training_patches.append(training_patched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded image:  (30, 30)\n",
      "Number of original patches:  16\n",
      "Number of recentered patches per original patch:  9\n",
      "Total number of patches for each image:  144\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of padded image: \", training_padded.shape)\n",
    "print(\"Number of original patches: \", len(training_patched))\n",
    "print(\"Number of recentered patches per original patch: \", len(training_patched[0]))\n",
    "print(\"Total number of patches for each image: \", len(training_patched) * len(training_patched[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_cluster(data,num_images=10000,num_grids=16,num_patches=9):\n",
    "    data_matrix_long = np.zeros((num_images*num_grids*num_patches,100))\n",
    "    z=0\n",
    "    for i in range(num_images):\n",
    "        for j in range(num_grids):\n",
    "            for k in range(num_patches):\n",
    "                data_matrix_long[z,:] = data[i][j][k]\n",
    "                z=z+1\n",
    "    #Finding the main 50 clusters\n",
    "    data_km_long = kmeans.predict(data_matrix_long)\n",
    "    data_50clusters= np.zeros((num_images,num_grids,num_patches))\n",
    "    z=0\n",
    "    for i in range(num_images):\n",
    "        for j in range(num_grids):\n",
    "            for k in range(num_patches):\n",
    "                data_50clusters[i,j,k] = data_km_long[z]\n",
    "                z=z+1\n",
    "    data_2500clusters= [[['000_000' for i in range(num_patches)] for j in range(num_grids)] for k in range(num_images)]\n",
    "    subcluster_data_fit = np.zeros((1,100))\n",
    "    z=1\n",
    "    #Finding the subclusters of each patch\n",
    "    for i in range(num_images):\n",
    "        for j in range(num_grids):\n",
    "            for k in range(num_patches):\n",
    "                cluster = data_50clusters[i,j,k]\n",
    "                subcluster_data_fit[0,:] = data[i][j][k]\n",
    "                fitted_centre=cluster_dict[str(int(cluster))].predict(subcluster_data_fit)\n",
    "                text=str(int(cluster))+'_'+str(fitted_centre[0])\n",
    "                data_2500clusters[i][j][k]= text\n",
    "                if z%10000==0 and z>=10000:\n",
    "                    print(str(z*100/(num_images*num_grids*num_patches))+'% done')\n",
    "                z=z+1\n",
    "    return(data_2500clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6944444444444444% done\n",
      "1.3888888888888888% done\n",
      "2.0833333333333335% done\n",
      "2.7777777777777777% done\n",
      "3.4722222222222223% done\n",
      "4.166666666666667% done\n",
      "4.861111111111111% done\n",
      "5.555555555555555% done\n",
      "6.25% done\n",
      "6.944444444444445% done\n",
      "7.638888888888889% done\n",
      "8.333333333333334% done\n",
      "9.027777777777779% done\n",
      "9.722222222222221% done\n",
      "10.416666666666666% done\n",
      "11.11111111111111% done\n",
      "11.805555555555555% done\n",
      "12.5% done\n",
      "13.194444444444445% done\n",
      "13.88888888888889% done\n",
      "14.583333333333334% done\n",
      "15.277777777777779% done\n",
      "15.972222222222221% done\n",
      "16.666666666666668% done\n",
      "17.36111111111111% done\n",
      "18.055555555555557% done\n",
      "18.75% done\n",
      "19.444444444444443% done\n",
      "20.13888888888889% done\n",
      "20.833333333333332% done\n",
      "21.52777777777778% done\n",
      "22.22222222222222% done\n",
      "22.916666666666668% done\n",
      "23.61111111111111% done\n",
      "24.305555555555557% done\n",
      "25.0% done\n",
      "25.694444444444443% done\n",
      "26.38888888888889% done\n",
      "27.083333333333332% done\n",
      "27.77777777777778% done\n",
      "28.47222222222222% done\n",
      "29.166666666666668% done\n",
      "29.86111111111111% done\n",
      "30.555555555555557% done\n",
      "31.25% done\n",
      "31.944444444444443% done\n",
      "32.638888888888886% done\n",
      "33.333333333333336% done\n",
      "34.02777777777778% done\n",
      "34.72222222222222% done\n",
      "35.416666666666664% done\n",
      "36.111111111111114% done\n",
      "36.80555555555556% done\n",
      "37.5% done\n",
      "38.19444444444444% done\n",
      "38.888888888888886% done\n",
      "39.583333333333336% done\n",
      "40.27777777777778% done\n",
      "40.97222222222222% done\n",
      "41.666666666666664% done\n",
      "42.361111111111114% done\n",
      "43.05555555555556% done\n",
      "43.75% done\n",
      "44.44444444444444% done\n",
      "45.138888888888886% done\n",
      "45.833333333333336% done\n",
      "46.52777777777778% done\n",
      "47.22222222222222% done\n",
      "47.916666666666664% done\n",
      "48.611111111111114% done\n",
      "49.30555555555556% done\n",
      "50.0% done\n",
      "50.69444444444444% done\n",
      "51.388888888888886% done\n",
      "52.083333333333336% done\n",
      "52.77777777777778% done\n",
      "53.47222222222222% done\n",
      "54.166666666666664% done\n",
      "54.861111111111114% done\n",
      "55.55555555555556% done\n",
      "56.25% done\n",
      "56.94444444444444% done\n",
      "57.638888888888886% done\n",
      "58.333333333333336% done\n",
      "59.02777777777778% done\n",
      "59.72222222222222% done\n",
      "60.416666666666664% done\n",
      "61.111111111111114% done\n",
      "61.80555555555556% done\n",
      "62.5% done\n",
      "63.19444444444444% done\n",
      "63.888888888888886% done\n",
      "64.58333333333333% done\n",
      "65.27777777777777% done\n",
      "65.97222222222223% done\n",
      "66.66666666666667% done\n",
      "67.36111111111111% done\n",
      "68.05555555555556% done\n",
      "68.75% done\n",
      "69.44444444444444% done\n",
      "70.13888888888889% done\n",
      "70.83333333333333% done\n",
      "71.52777777777777% done\n",
      "72.22222222222223% done\n",
      "72.91666666666667% done\n",
      "73.61111111111111% done\n",
      "74.30555555555556% done\n",
      "75.0% done\n",
      "75.69444444444444% done\n",
      "76.38888888888889% done\n",
      "77.08333333333333% done\n",
      "77.77777777777777% done\n",
      "78.47222222222223% done\n",
      "79.16666666666667% done\n",
      "79.86111111111111% done\n",
      "80.55555555555556% done\n",
      "81.25% done\n",
      "81.94444444444444% done\n",
      "82.63888888888889% done\n",
      "83.33333333333333% done\n",
      "84.02777777777777% done\n",
      "84.72222222222223% done\n",
      "85.41666666666667% done\n",
      "86.11111111111111% done\n",
      "86.80555555555556% done\n",
      "87.5% done\n",
      "88.19444444444444% done\n",
      "88.88888888888889% done\n",
      "89.58333333333333% done\n",
      "90.27777777777777% done\n",
      "90.97222222222223% done\n",
      "91.66666666666667% done\n",
      "92.36111111111111% done\n",
      "93.05555555555556% done\n",
      "93.75% done\n",
      "94.44444444444444% done\n",
      "95.13888888888889% done\n",
      "95.83333333333333% done\n",
      "96.52777777777777% done\n",
      "97.22222222222223% done\n",
      "97.91666666666667% done\n",
      "98.61111111111111% done\n",
      "99.30555555555556% done\n",
      "100.0% done\n"
     ]
    }
   ],
   "source": [
    "test_2500clusters = finding_cluster(testing_patches,10000,16,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0_0', '0_1', '0_10', ..., '9_7', '9_8', '9_9'], dtype='<U5')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_2500clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_patch_creation(data,num_images=10000,num_grids=16,num_patches=9):\n",
    "    colnames=['image_num']\n",
    "    for i in range(50):\n",
    "        for j in range(50):\n",
    "            colnames.append(str(i)+'_'+str(j))\n",
    "    df=np.zeros((num_images,2501))\n",
    "    hist_patches = pd.DataFrame(df,columns = colnames)\n",
    "    hist_patches['image_num']=range(num_images)\n",
    "    z=1\n",
    "    for i in range(num_images):\n",
    "        for j in range(16):\n",
    "            for k in range(9):\n",
    "                hist_patches.loc[i,data[i][j][k]]+=1\n",
    "                if z%10000==0 and z>=10000:\n",
    "                    print(str(z*100/(num_images*num_grids*num_patches))+'% done')\n",
    "                z=z+1\n",
    "    return(hist_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6944444444444444% done\n",
      "1.3888888888888888% done\n",
      "2.0833333333333335% done\n",
      "2.7777777777777777% done\n",
      "3.4722222222222223% done\n",
      "4.166666666666667% done\n",
      "4.861111111111111% done\n",
      "5.555555555555555% done\n",
      "6.25% done\n",
      "6.944444444444445% done\n",
      "7.638888888888889% done\n",
      "8.333333333333334% done\n",
      "9.027777777777779% done\n",
      "9.722222222222221% done\n",
      "10.416666666666666% done\n",
      "11.11111111111111% done\n",
      "11.805555555555555% done\n",
      "12.5% done\n",
      "13.194444444444445% done\n",
      "13.88888888888889% done\n",
      "14.583333333333334% done\n",
      "15.277777777777779% done\n",
      "15.972222222222221% done\n",
      "16.666666666666668% done\n",
      "17.36111111111111% done\n",
      "18.055555555555557% done\n",
      "18.75% done\n",
      "19.444444444444443% done\n",
      "20.13888888888889% done\n",
      "20.833333333333332% done\n",
      "21.52777777777778% done\n",
      "22.22222222222222% done\n",
      "22.916666666666668% done\n",
      "23.61111111111111% done\n",
      "24.305555555555557% done\n",
      "25.0% done\n",
      "25.694444444444443% done\n",
      "26.38888888888889% done\n",
      "27.083333333333332% done\n",
      "27.77777777777778% done\n",
      "28.47222222222222% done\n",
      "29.166666666666668% done\n",
      "29.86111111111111% done\n",
      "30.555555555555557% done\n",
      "31.25% done\n",
      "31.944444444444443% done\n",
      "32.638888888888886% done\n",
      "33.333333333333336% done\n",
      "34.02777777777778% done\n",
      "34.72222222222222% done\n",
      "35.416666666666664% done\n",
      "36.111111111111114% done\n",
      "36.80555555555556% done\n",
      "37.5% done\n",
      "38.19444444444444% done\n",
      "38.888888888888886% done\n",
      "39.583333333333336% done\n",
      "40.27777777777778% done\n",
      "40.97222222222222% done\n",
      "41.666666666666664% done\n",
      "42.361111111111114% done\n",
      "43.05555555555556% done\n",
      "43.75% done\n",
      "44.44444444444444% done\n",
      "45.138888888888886% done\n",
      "45.833333333333336% done\n",
      "46.52777777777778% done\n",
      "47.22222222222222% done\n",
      "47.916666666666664% done\n",
      "48.611111111111114% done\n",
      "49.30555555555556% done\n",
      "50.0% done\n",
      "50.69444444444444% done\n",
      "51.388888888888886% done\n",
      "52.083333333333336% done\n",
      "52.77777777777778% done\n",
      "53.47222222222222% done\n",
      "54.166666666666664% done\n",
      "54.861111111111114% done\n",
      "55.55555555555556% done\n",
      "56.25% done\n",
      "56.94444444444444% done\n",
      "57.638888888888886% done\n",
      "58.333333333333336% done\n",
      "59.02777777777778% done\n",
      "59.72222222222222% done\n",
      "60.416666666666664% done\n",
      "61.111111111111114% done\n",
      "61.80555555555556% done\n",
      "62.5% done\n",
      "63.19444444444444% done\n",
      "63.888888888888886% done\n",
      "64.58333333333333% done\n",
      "65.27777777777777% done\n",
      "65.97222222222223% done\n",
      "66.66666666666667% done\n",
      "67.36111111111111% done\n",
      "68.05555555555556% done\n",
      "68.75% done\n",
      "69.44444444444444% done\n",
      "70.13888888888889% done\n",
      "70.83333333333333% done\n",
      "71.52777777777777% done\n",
      "72.22222222222223% done\n",
      "72.91666666666667% done\n",
      "73.61111111111111% done\n",
      "74.30555555555556% done\n",
      "75.0% done\n",
      "75.69444444444444% done\n",
      "76.38888888888889% done\n",
      "77.08333333333333% done\n",
      "77.77777777777777% done\n",
      "78.47222222222223% done\n",
      "79.16666666666667% done\n",
      "79.86111111111111% done\n",
      "80.55555555555556% done\n",
      "81.25% done\n",
      "81.94444444444444% done\n",
      "82.63888888888889% done\n",
      "83.33333333333333% done\n",
      "84.02777777777777% done\n",
      "84.72222222222223% done\n",
      "85.41666666666667% done\n",
      "86.11111111111111% done\n",
      "86.80555555555556% done\n",
      "87.5% done\n",
      "88.19444444444444% done\n",
      "88.88888888888889% done\n",
      "89.58333333333333% done\n",
      "90.27777777777777% done\n",
      "90.97222222222223% done\n",
      "91.66666666666667% done\n",
      "92.36111111111111% done\n",
      "93.05555555555556% done\n",
      "93.75% done\n",
      "94.44444444444444% done\n",
      "95.13888888888889% done\n",
      "95.83333333333333% done\n",
      "96.52777777777777% done\n",
      "97.22222222222223% done\n",
      "97.91666666666667% done\n",
      "98.61111111111111% done\n",
      "99.30555555555556% done\n",
      "100.0% done\n"
     ]
    }
   ],
   "source": [
    "test_hist_patches=histogram_patch_creation(test_2500clusters,10000,16,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1574074074074074% done\n",
      "2.314814814814815% done\n",
      "3.4722222222222223% done\n",
      "4.62962962962963% done\n",
      "5.787037037037037% done\n",
      "6.944444444444445% done\n",
      "8.101851851851851% done\n",
      "9.25925925925926% done\n",
      "10.416666666666666% done\n",
      "11.574074074074074% done\n",
      "12.731481481481481% done\n",
      "13.88888888888889% done\n",
      "15.046296296296296% done\n",
      "16.203703703703702% done\n",
      "17.36111111111111% done\n",
      "18.51851851851852% done\n",
      "19.675925925925927% done\n",
      "20.833333333333332% done\n",
      "21.99074074074074% done\n",
      "23.14814814814815% done\n",
      "24.305555555555557% done\n",
      "25.462962962962962% done\n",
      "26.62037037037037% done\n",
      "27.77777777777778% done\n",
      "28.935185185185187% done\n",
      "30.09259259259259% done\n",
      "31.25% done\n",
      "32.407407407407405% done\n",
      "33.56481481481482% done\n",
      "34.72222222222222% done\n",
      "35.879629629629626% done\n",
      "37.03703703703704% done\n",
      "38.19444444444444% done\n",
      "39.351851851851855% done\n",
      "40.50925925925926% done\n",
      "41.666666666666664% done\n",
      "42.824074074074076% done\n",
      "43.98148148148148% done\n",
      "45.138888888888886% done\n",
      "46.2962962962963% done\n",
      "47.4537037037037% done\n",
      "48.611111111111114% done\n",
      "49.76851851851852% done\n",
      "50.925925925925924% done\n",
      "52.083333333333336% done\n",
      "53.24074074074074% done\n",
      "54.398148148148145% done\n",
      "55.55555555555556% done\n",
      "56.71296296296296% done\n",
      "57.870370370370374% done\n",
      "59.02777777777778% done\n",
      "60.18518518518518% done\n",
      "61.342592592592595% done\n",
      "62.5% done\n",
      "63.657407407407405% done\n",
      "64.81481481481481% done\n",
      "65.97222222222223% done\n",
      "67.12962962962963% done\n",
      "68.28703703703704% done\n",
      "69.44444444444444% done\n",
      "70.60185185185185% done\n",
      "71.75925925925925% done\n",
      "72.91666666666667% done\n",
      "74.07407407407408% done\n",
      "75.23148148148148% done\n",
      "76.38888888888889% done\n",
      "77.54629629629629% done\n",
      "78.70370370370371% done\n",
      "79.86111111111111% done\n",
      "81.01851851851852% done\n",
      "82.17592592592592% done\n",
      "83.33333333333333% done\n",
      "84.49074074074075% done\n",
      "85.64814814814815% done\n",
      "86.80555555555556% done\n",
      "87.96296296296296% done\n",
      "89.12037037037037% done\n",
      "90.27777777777777% done\n",
      "91.43518518518519% done\n",
      "92.5925925925926% done\n",
      "93.75% done\n",
      "94.9074074074074% done\n",
      "96.06481481481481% done\n",
      "97.22222222222223% done\n",
      "98.37962962962963% done\n",
      "99.53703703703704% done\n"
     ]
    }
   ],
   "source": [
    "train_2500clusters = finding_cluster(training_patches, 6000, 16, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1574074074074074% done\n",
      "2.314814814814815% done\n",
      "3.4722222222222223% done\n",
      "4.62962962962963% done\n",
      "5.787037037037037% done\n",
      "6.944444444444445% done\n",
      "8.101851851851851% done\n",
      "9.25925925925926% done\n",
      "10.416666666666666% done\n",
      "11.574074074074074% done\n",
      "12.731481481481481% done\n",
      "13.88888888888889% done\n",
      "15.046296296296296% done\n",
      "16.203703703703702% done\n",
      "17.36111111111111% done\n",
      "18.51851851851852% done\n",
      "19.675925925925927% done\n",
      "20.833333333333332% done\n",
      "21.99074074074074% done\n",
      "23.14814814814815% done\n",
      "24.305555555555557% done\n",
      "25.462962962962962% done\n",
      "26.62037037037037% done\n",
      "27.77777777777778% done\n",
      "28.935185185185187% done\n",
      "30.09259259259259% done\n",
      "31.25% done\n",
      "32.407407407407405% done\n",
      "33.56481481481482% done\n",
      "34.72222222222222% done\n",
      "35.879629629629626% done\n",
      "37.03703703703704% done\n",
      "38.19444444444444% done\n",
      "39.351851851851855% done\n",
      "40.50925925925926% done\n",
      "41.666666666666664% done\n",
      "42.824074074074076% done\n",
      "43.98148148148148% done\n",
      "45.138888888888886% done\n",
      "46.2962962962963% done\n",
      "47.4537037037037% done\n",
      "48.611111111111114% done\n",
      "49.76851851851852% done\n",
      "50.925925925925924% done\n",
      "52.083333333333336% done\n",
      "53.24074074074074% done\n",
      "54.398148148148145% done\n",
      "55.55555555555556% done\n",
      "56.71296296296296% done\n",
      "57.870370370370374% done\n",
      "59.02777777777778% done\n",
      "60.18518518518518% done\n",
      "61.342592592592595% done\n",
      "62.5% done\n",
      "63.657407407407405% done\n",
      "64.81481481481481% done\n",
      "65.97222222222223% done\n",
      "67.12962962962963% done\n",
      "68.28703703703704% done\n",
      "69.44444444444444% done\n",
      "70.60185185185185% done\n",
      "71.75925925925925% done\n",
      "72.91666666666667% done\n",
      "74.07407407407408% done\n",
      "75.23148148148148% done\n",
      "76.38888888888889% done\n",
      "77.54629629629629% done\n",
      "78.70370370370371% done\n",
      "79.86111111111111% done\n",
      "81.01851851851852% done\n",
      "82.17592592592592% done\n",
      "83.33333333333333% done\n",
      "84.49074074074075% done\n",
      "85.64814814814815% done\n",
      "86.80555555555556% done\n",
      "87.96296296296296% done\n",
      "89.12037037037037% done\n",
      "90.27777777777777% done\n",
      "91.43518518518519% done\n",
      "92.5925925925926% done\n",
      "93.75% done\n",
      "94.9074074074074% done\n",
      "96.06481481481481% done\n",
      "97.22222222222223% done\n",
      "98.37962962962963% done\n",
      "99.53703703703704% done\n"
     ]
    }
   ],
   "source": [
    "train_hist_patches=histogram_patch_creation(train_2500clusters,6000,16,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_num</th>\n",
       "      <th>0_0</th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>0_6</th>\n",
       "      <th>0_7</th>\n",
       "      <th>0_8</th>\n",
       "      <th>...</th>\n",
       "      <th>49_40</th>\n",
       "      <th>49_41</th>\n",
       "      <th>49_42</th>\n",
       "      <th>49_43</th>\n",
       "      <th>49_44</th>\n",
       "      <th>49_45</th>\n",
       "      <th>49_46</th>\n",
       "      <th>49_47</th>\n",
       "      <th>49_48</th>\n",
       "      <th>49_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_num  0_0  0_1  0_2  0_3  0_4  0_5  0_6  0_7  0_8  ...  49_40  \\\n",
       "0             0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "1             1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "2             2  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...    0.0   \n",
       "3             3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "4             4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...    0.0   \n",
       "...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   \n",
       "9995       9995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...    0.0   \n",
       "9996       9996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "9997       9997  0.0  0.0  0.0  1.0  2.0  0.0  1.0  0.0  0.0  ...    0.0   \n",
       "9998       9998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "9999       9999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "      49_41  49_42  49_43  49_44  49_45  49_46  49_47  49_48  49_49  \n",
       "0       0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4       0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0  \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "9995    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "9996    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "9997    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
       "9998    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "9999    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[10000 rows x 2501 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hist_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_2500clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_2500clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
