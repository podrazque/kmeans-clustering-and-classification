{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import seaborn as sns\n",
    "import pickle, gzip\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from sklearn.cluster import KMeans\n",
    "import sys\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_python2():\n",
    "    with gzip.open('mnist.pkl.gz', 'rb') as fd:\n",
    "        #u = pickle._Unpickler(fd)\n",
    "        #u.encoding = 'latin1'\n",
    "        train_set, valid_set, test_set = pickle.load(fd)\n",
    "        #u.load()\n",
    "        return train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_python3():\n",
    "    with gzip.open('mnist.pkl.gz', 'rb') as fd:\n",
    "        u = pickle._Unpickler(fd)\n",
    "        u.encoding = 'latin1'\n",
    "        train_set, valid_set, test_set = u.load()\n",
    "        return train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(sys.version[0]=='3'):\n",
    "    train_set, valid_set, test_set = get_data_python3()\n",
    "elif(sys.version[0]=='2'):\n",
    "    train_set, valid_set, test_set = get_data_python2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train and val\n",
    "train_set = (np.concatenate([train_set[0], valid_set[0]], axis=0), \n",
    "                np.concatenate([train_set[1], valid_set[1]], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Size of training set:', 60000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training set:\", len(train_set[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Size of each training set item (28x28 image 1-d array): ', 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of each training set item (28x28 image 1-d array): \", len(train_set[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshaping each 784 1-d array into 28x28 2-d array\n",
    "train_set[0].reshape(60000,28,28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating 4x4 grid of 10x10 patches\n",
    "def patch_creation(image):\n",
    "    patches = []\n",
    "    x=[0,6,12,18]\n",
    "    y=[0,6,12,18]\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            patch = image[i:i+10,j:j+10].reshape(-1,100)\n",
    "            patches.append(patch)\n",
    "    return(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(test): \n",
    "    fig = plt.figure(figsize=(4., 4.))\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(4, 4),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes in inch.\n",
    "                     )\n",
    "\n",
    "    for ax, im in zip(grid, [test[0].reshape(10, 10), test[1].reshape(10, 10), test[2].reshape(10, 10), test[3].reshape(10, 10),\n",
    "                            test[4].reshape(10, 10), test[5].reshape(10, 10), test[6].reshape(10, 10), test[7].reshape(10, 10),\n",
    "                            test[8].reshape(10, 10), test[9].reshape(10, 10),test[10].reshape(10, 10),test[11].reshape(10, 10),\n",
    "                            test[12].reshape(10, 10), test[13].reshape(10, 10),test[14].reshape(10, 10),test[15].reshape(10, 10)]):\n",
    "        # Iterating over the grid returns the Axes.\n",
    "        ax.imshow(im, cmap='Greys_r')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is simply here to make sure that our grid creation works correctly\n",
    "def test_image():\n",
    "    #fetch one image\n",
    "    image = train_set[0][1].reshape(28,28)\n",
    "    \n",
    "    print(\"Image shape: \",image.shape)\n",
    "    \n",
    "    #create 16 - 10x10 patches\n",
    "    test = patch_creation(image)\n",
    "    \n",
    "    print(\"Num patches: \", len(test))\n",
    "    \n",
    "    #plotting the test image to see create patches\n",
    "    plot_image(test)\n",
    "    \n",
    "    #plt.imshow(image.reshape(28, 28), cmap='Greys_r')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Image shape: ', (28, 28))\n",
      "('Num patches: ', 16)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAEq1JREFUeJzt3V9sVPW2B/Dv6iBtqTVGWkkEKgqouYlBjw16UxHwCukND/jvAc+DiVHh4ZCoT3LUJw1gfDDRxD/hgQdRgg9Q9QEBwSjGa0Lb5BoBAblNkZ5KADFQBCmFdR865czMb0/7m87+7T2z+v0kDd3L3b1+i3Gx9+zu+f1EVUFENtWkPQAiCocNTmQYG5zIMDY4kWFscCLD2OBEhrHBiQxjgxMZ5tXgItIuIodF5KiIrAk9KCKKh4z1JJuIZAAcAbAEQB+ATgBPqerBUX7GwuNxp1W1Oeo/sL6qMGHry+VzBp8P4Kiq9qjqIIAtAJaXO7oqcCztAQTG+qqbV30+DT4dwPGc7b5sjIgq3CSPfSQi5lziiMhKACvLHlGFYn3VzXp9RanqqF8A/hPAzpztfwL45xg/owa+ulhfVX9N2Ppyv3wu0TsBzBWR20RkMoAVAL7w+DkiStmYl+iqOiQiqwHsBJABsFFVDwQfGRGVzec9OFR1O4DtgcdCRDHjk2xEhrHBiQxjgxMZxgYnMowNTmQYG5zIMDY4kWFscCLD2OBEhrHBiQxjgxMZxgYnMszrwyZU3RYtWuTEvvnmm8Ryvfbaa3nbDz/8sLPP119/7cRef/11J7Z3797xDy7rjjvuwPvvv59IrrTxDE5kGBucyDA2OJFhY86LDgAi0gtgAMAVAEOq2jrG/mMftPJ1F6uzkutra2tzYrt373Zi9fX1Zdfnm2vy5Mk+h3NcunTJiU2ZMsX3x4vW19raqvv27YszVxqK1perlJtsi1X1dBkDIqKE8RKdyDDfBlcAu0SkOzu/tENEVopIl4h0xTe8ysH6qltufadOnUp7OInxbfA2Vf0bgP8G8A8ReahwB1XdoKqtPu8LqhHrq2659TU3j7mklxm+s6r2Z/88KSIdGF6vrPqfAqhyjzzyiBPbtm2bE6urqwuSa+vWrU6strbWiRXeyB0cHHT2uXLlihOrr693Yu3t7U4s6iGZqBwjrl69iosXLyaSK21jnsFFpEFEGke+B7AUwP7QAyOi8vmcwacB6BCRkf03q+qOoKMiolj4rGzSA2BeAmMhopjx12REhnk9yVbyQSv4Sa8SpPYkW0NDgxNbvHixE/vkk0+cWGNjoxPLvr0qjBWt78Ybb9QFCxbkxT7++ONx5yr8f+z48ePOPuvWrXNiH3zwgdfx33nnHSf20ksvFa2vublZH3/88ThzRaUJzetJNp7BiQxjgxMZxgYnMowNTmQYp2yqQNu3u0uxF970CmnOnDn4/PPPgx1/5syZTizqht2RI0ec2J133unEWltLe7o2k8k4+ULlShvP4ESGscGJDGODExnGBicyjDfZKkDhXOLz58939ol6qipK1M2ijo6Oksfkk+/w4cNO7LPPPnNiL7/8ct72+fPnnX1++OEHJ3bmzBkntnHjRifm+3eTm78wX6hcaeMZnMgwNjiRYWxwIsPY4ESGhfq46CkAxwA0AQg9l3qoHLeqauTsfKwvVmnWFzL/iMTryxWkwa8dXKQr9CydSeRIMzfrCyt0/rTr4yU6kWFscCLDQjf4hsDHTypHmrlZX3XnT7W+oO/BiShdXmdwEWkXkcMiclRE1oQeFBHFY8wzuIhkABwBsARAH4BOAE+p6sHwwyOicvh82GQ+gKPZBRAgIlsALAdQtMGNTJt8epTfo1ZEfVGzoMyZM8eJ1dS4F2rd3d0l1ReVa/bs2U4sk8kUGe2/RZ1UomJR4/7ll1+c2MDAQNTxitbX1NSkLS0tceaKShNa0fpy+TT4dAC5E1n3Abh/vKOqIsfG3iVd99/vvgxRiw8Wmb+8pPqickUtPhiVK87FB5ctW+bEiiwIWLS+lpYWfPfdd3HmKpYqJK/Xz6fBoz4f5/yTlV03PHLtcAtYX3XLrS9qTjirfG6y9QHI/RuZAaC/cKeJtL502mMJYSLV19TUlPZwEuNzk20Shm+y/ReAf2H4JtvfVfXAKD9TEe9Ry8Sli3Jw6aJRc0WlCc1r6SKf1UWHRGQ1gJ0AMgA2jtbcRFQ5vKZsUtXtANzJuomoovFZdCLD2OBEhnFW1QrEpYuGcemi8vEMTmQYG5zIMDY4kWFscCLDeJOtAnDpIi5dFArP4ESGscGJDGODExnGBicyLNTSRVX1cdG2tjYn9v333wf5uGhUrt27d+dt19bWeh3rxx9/dGIPPfSQE3v00Ued2KZNm4rW19raqvv27Rsz18KFC71y3XvvvXnbb731lrPPiRMnoobiuHr1qhO7fPmyE6utrS379fPNtWTJkrztvXv3+hy+XF4fF+UZnMgwNjiRYWxwIsO8HnQRkV4AAwCuABiq5nm77r77bie2fv16Jxb1XjZUrrq6urztCxcuOPucPXvWiUVNMxQ1re+mTZtGHWehy5cvO++JP/zww3HnKjV/qSZNSu55rahcb7zxRt521L2JtJTyN7NYVUOvFU1EMeIlOpFhvg2uAHaJSHd2fmmHiKwUkS4R6YpveJVjItX3+++/pz2c2Fl//YrxvURvU9V+EbkZwFcickhV837Zp6obkF0qtdp+D+5jItU3b9480/VZfP2K8Z1VtT/750kR6cDwemWJ/Da/HIU3rwDgo48+cmLz5s1LNdelS5fytp977jlnnz179jixKVOmlDJEbwcPHnQeTgmVy4Jbbrkl7SEUNeYluog0iEjjyPcAlgLYH3pgRFQ+nzP4NAAd2c/BTgKwWVV3BB0VEcXCZ2WTHgDlX8MSUeL4azIiw0xP2VQ4FRIQzw21uHOtWLEibztq2qMkDQ0N4eTJk6mOgeLBMziRYWxwIsPY4ESGscGJDDN9ky3q45RR81pHzSWeZK60b6pVkyTnJffNVclzpfMMTmQYG5zIMDY4kWFscCLDzNxke/rpp53YjBkznFjUPPBbt24tKdfUqVOxbNmyRHJRvqi/0xBz+5eS66effgqSPw48gxMZxgYnMowNTmQYG5zIsFCLD54CcAxAE4DQc6mHynGrqjZH/QfWF6s06wuZf0Ti9eUK0uDXDi7SFXoVlCRypJmb9YUVOn/a9fESncgwNjiRYaEbfEPg4yeVI83crK+686daX9D34ESULq8zuIi0i8hhETkqImtCD4qI4jHmGVxEMgCOAFgCoA9AJ4CnVPVg+OERUTl8PmwyH8DR7AIIEJEtAJYDKNrglbK4W9RMG3fddZcTi1p3q7u7+/Qov0d16isnV+E/sr29vc4+586dc2I1Ne4F2ODgoBMromh9NTU1mslk4swVm/vuu89rv1Jfv3JyFa4tt39/Iit7Fa0vl0+DTwdwPGe7D8D94x1Vkmpra53Y5s2bnVjU/OU1NTXHnGCgXIWN8swzzzj7+C4+GPWPQxFF68tkMrjpppvizBWbzs5OJxZ1FZrJZEp6/crJ1dPTk7c9d+7cclP78KrPp8GjJpyKOoOtBBC5drgFE6m+qLN1tbP++hXj0+B9AGbmbM8A0F+4k/X1lydSfdddd53p+iy+fsX4/FPdCWCuiNwmIpMBrADwRdhhEVEcfFYXHRKR1QB2AsgA2KiqB4KPLAZcm2x8uDaZHV5TNqnqdgDbA4+FiGJm724KEV3DBicyjA1OZJiZaZOjcG0ye7g2WWl4BicyjA1OZBgbnMgwNjiRYWZusnFtsomBa5OVhmdwIsPY4ESGscGJDGODExlm5iZbQ0ODEyucVwwALly44MSinkIbTU1NjZMvVK6Joq6uzon5/l39/PPPJeUSEWeKrXJyRd3grRQ8gxMZxgYnMszrEl1EegEMALgCYCjN1RKJyF8p78EXq2rotaKDGxoacmLHjx+P2LO6clWTqPfb7777rhOLem8bNT/82rVrS8rf0tKCV199NbZcAwMDJeVPEi/RiQzzbXAFsEtEurPzSxNRFfC9RG9T1X4RuRnAVyJySFX35u5gfWL53Pquv/76lEcTv4n0+hWu2mKZ1xlcVfuzf54E0IHh9coK99mgqq1Wb8Dl1ldfX5/2cGI3kV6/xsbGtIeTmDHP4CLSAKBGVQey3y8F8HrwkQWye/duk7kqWVtbW972unXrnH0efPBBJxa1NtgDDzxQ9niamprw7LPPJpIrbT6X6NMAdGTnnZoEYLOq7gg6KiKKhc/KJj0AwiwHQkRB8ddkRIaxwYkMM/Npsqi5qaNiS5YsCZIvZK5yvfnmm05szZo1QXKtX7/eib344ot524Wf5AKAb7/91oktXrw4voHlGBgYwN69eb/lDZYrbTyDExnGBicyjA1OZBgbnMgwMzfZfOewjnqOPGqu8ieeeKKkfOXkevvtt/O2+/v7nX3a29ud2MqV7qPjt99+uxO74YYbnNhoN9mam5ud+p9//nlnv9mzZ3vlOnv2bN52V1eXs0/UjcBQTpw4kWi+NPEMTmQYG5zIMDY4kWFscCLDzNxk8xX1xNljjz2Waq6lS5fmbf/111/OPlOnTh33OHp6ekrav6WlBe+9915sufbs2ZO3vWrVqnEdOy7nzp3Dzp07Ux1DUngGJzKMDU5kGBucyDA2OJFhEvUEVtkHFTkF4BiAJgChF0sIleNWVW2O+g+sL1Zp1hcy/4jE68sVpMGvHVykK/QsnUnkSDM36wsrdP606+MlOpFhbHAiw0I3+IbAx08qR5q5WV9150+1vqDvwYkoXV5ncBFpF5HDInJURMLM1kdEsRvzDC4iGQBHACwB0AegE8BTqnpwlJ9J/LKgudn9jUFLS4sT++OPP5xYkWe1Txf7NUR9fb0Wrm9VZq40FK0v7tevoaEhb3vGjBnOPlGTY/z5559O7NChQ75pi9bX1NSks2bNijNXGorWl8vnwybzARzNrnACEdkCYDmAog2ehieffNKJRX1gYtu2bV4/i3//ntTR2Njo/EyZudJQtL643XPPPXnbUVMrR61NFjXzy/z5zrqXxRStb9asWc6xo9YmKyFXGrxeP59L9OkAjuds92VjeURkpYh0iYj7qhiQW9/FixfTHk7sJtLrd+rUqbSHkxifBnc/8wg4l3ATaflZLh9cfXLri3o7Z5VPg/cBmJmzPQOAOysgEVUcn/fgnQDmishtAP4FYAWAvwcd1Thw6aLikly6KCrXCy+8kLddV1fn7BO1dNGiRYtiG1eu8+fPO0sXLVy4MEiutPksHzwkIqsB7ASQAbBRVQ8EHxkRlc1ryiZV3Q5ge+CxEFHM+Cw6kWFscCLDzMyqyqWLhsW1dFHhAznl5Cpcuqi7u9vZJ+rhl1B+++03rFu3LrF8aeIZnMgwNjiRYWxwIsPY4ESGmbnJ5otLF40t9NJFUTfsksSli4jIBDY4kWFscCLD2OBEhpm5yfbll186sV9//dWJRc2dVqqzZ886+crJVfjEW+EcZsVEzSwT9fcQxzRRSeai+PAMTmQYG5zIMK9LdBHpBTAA4AqAIavzdhFZU8p78MWqGnop2XHr7e11YgsWLHBir7zyihNbtWpVSbkGBwedfKFyjfj000+d2Nq1a53Y/v37x3X8XGfOnHHyhcpFYfESncgw3wZXALtEpFtE0n3OkIi8+V6it6lqv4jcDOArETmkqnnTUmYb32zzT6T6mpqaUh5N/Ky/fsV4ncFVtT/750kAHRhezqhwnwkzcX7aYwkht77CddcssP76FaWqo34BaADQmPP9/wBoH+Nn1MBXF+ur6q8JW1/ul88l+jQAHdmPPk4CsFlVd3j8HBGlzGfhgx4A8xIYCxHFjL8mIzKMDU5kGBucyDA2OJFhbHAiw9jgRIaxwYkMY4MTGcYGJzKMDU5kGBucyDA2OJFhbHAiw9jgRIaxwYkMY4MTGcYGJzIs1OKDpwEcA9CU/T6kUDluHeW/sb74pFlfyPwj0qjvGslOQheEiHSFnsUyiRxp5mZ9YYXOn3Z9vEQnMowNTmRY6AbfEPj4SeVIMzfrq+78qdYX9D04EaWLl+hEhgVrcBFpF5HDInJURNYEOH6viPwkIv8rIl1xH98jP+sr7/im68vmSLVGABhzbaPxfAHIAPg/ALcDmAzgRwD/EXOOXgBNIcbP+lhftdc48hXqDD4fwFFV7VHVQQBbACwPlCsNrK+6Wa/vmlANPh3A8ZztvmwsTgpgl4h0Z9d+ThLrK5/1+oB0awQQ7lFViYjFfbu+TVX7ReRmAF+JyCFV3RtzjmJYX/ms1wekWyOAcGfwPgAzc7ZnAOiPM4Gq9mf/PAmgA8OXXUlhfWWyXh+Qeo0AwjV4J4C5InKbiEwGsALAF3EdXEQaRKRx5HsASwHsj+v4HlhfGazXB1REjQACXaKr6pCIrAawE8N3LDeq6oEYU0wD0CEiwHANm1V1R4zHHxXrK5v1+oCUaxzBJ9mIDOOTbESGscGJDGODExnGBicyjA1OZBgbnMgwNjiRYWxwIsP+H0CWo/v5i+x/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 32 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping each 784 1-d array into 28x28 2-d array and creating patches for each image\n",
    "training_patches=[]\n",
    "for i in range(60000):\n",
    "    image = train_set[0][i].reshape(28,28)\n",
    "    training_patches.append(patch_creation(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amount of training images: ', 60000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Amount of training images: \", len(training_patches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amount of matrices (patches) in each training image: ', 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Amount of matrices (patches) in each training image: \", len(training_patches[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing 1 patch from the 16 previously created for each image at random and appending to \n",
    "#training list\n",
    "train_cluster=[]\n",
    "for i in range(60000):\n",
    "    n = random.randint(0, 15)\n",
    "    train_cluster.append(training_patches[i][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a list of 6000 numbers where each is between 0 - 59999\n",
    "indices = random.sample(range(60000), 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending randomly sampled patches using the previously created list of indices\n",
    "train_cluster_sample=[]\n",
    "for ind in indices:\n",
    "    train_cluster_sample.append(train_cluster[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Length of our randomly sampled patches: ', 6000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of our randomly sampled patches: \", len(train_cluster_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a 6000x100 matrix of zeros that where each row will be one of our samples\n",
    "training_matrix = np.zeros((6000,100))\n",
    "for i in range(6000):\n",
    "    #making eacch row a random patch\n",
    "    training_matrix[i,:] = train_cluster_sample[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create kmeans object\n",
    "kmeans = KMeans(n_clusters=50)\n",
    "# fit kmeans object to data\n",
    "kmeans.fit(training_matrix)\n",
    "# save new clusters for chart\n",
    "y_km = kmeans.predict(training_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_matrix_60k = np.zeros((60000,100))\n",
    "for i in range(60000):\n",
    "    training_matrix_60k[i,:] = train_cluster[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_km_60k = kmeans.predict(training_matrix_60k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster_dict=[]\n",
    "cluster_dict = {}\n",
    "for i in range(50):\n",
    "    key = str(i)\n",
    "    subtrain_matrix = training_matrix_60k[y_km_60k==i,:]\n",
    "    kmeans_sub = KMeans(n_clusters=50)\n",
    "    kmeans_sub.fit(subtrain_matrix)\n",
    "    cluster_dict[key] = kmeans_sub \n",
    "    y_km_sub = kmeans_sub.predict(subtrain_matrix)\n",
    "    #cluster_dict.append(y_km_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_with(vector, pad_width, iaxis, kwargs):\n",
    "    pad_value = kwargs.get('padder', 0)\n",
    "    vector[:pad_width[0]] = pad_value\n",
    "    vector[-pad_width[1]:] = pad_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_b(image):\n",
    "    patches16 = []\n",
    "    x_ = [0, 1, 2]\n",
    "    y_ = [0, 1, 2]\n",
    "    x=[0,6,12,18]\n",
    "    y=[0,6,12,18]\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            patches9 = []\n",
    "            for k in x_:\n",
    "                for l in y_:\n",
    "                    patch = image[i+k:i+k+10, j+l:j+l+10].reshape(-1,100)\n",
    "                    patches9.append(patch)\n",
    "            patches16.append(patches9)\n",
    "    return patches16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_patches = []\n",
    "testing_labels = []\n",
    "for i in range(10000):\n",
    "    testing_reshaped = test_set[0][i].reshape(28,28)\n",
    "    testing_labels.append(test_set[1][i])\n",
    "    testing_padded = np.pad(testing_reshaped, 1, pad_with)\n",
    "    testing_patched = patch_b(testing_padded)\n",
    "    testing_patches.append(testing_patched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of padded image: ', (30, 30))\n",
      "('Number of original patches: ', 16)\n",
      "('Number of recentered patches per original patch: ', 9)\n",
      "('Total number of patches for each image: ', 144)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of padded image: \", testing_padded.shape)\n",
    "print(\"Number of original patches: \", len(testing_patched))\n",
    "print(\"Number of recentered patches per original patch: \", len(testing_patched[0]))\n",
    "print(\"Total number of patches for each image: \", len(testing_patched) * len(testing_patched[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_patches = []\n",
    "random_indices = random.sample(range(60000), 6000)\n",
    "training_labels = []\n",
    "for i in random_indices:\n",
    "    training_reshaped = train_set[0][i].reshape(28,28)\n",
    "    training_labels.append(train_set[1][i])\n",
    "    training_padded = np.pad(training_reshaped, 1, pad_with)\n",
    "    training_patched = patch_b(training_padded)\n",
    "    training_patches.append(training_patched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of padded image: ', (30, 30))\n",
      "('Number of original patches: ', 16)\n",
      "('Number of recentered patches per original patch: ', 9)\n",
      "('Total number of patches for each image: ', 144)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of padded image: \", training_padded.shape)\n",
    "print(\"Number of original patches: \", len(training_patched))\n",
    "print(\"Number of recentered patches per original patch: \", len(training_patched[0]))\n",
    "print(\"Total number of patches for each image: \", len(training_patched) * len(training_patched[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_cluster(data,num_images=10000,num_grids=16,num_patches=9):\n",
    "    data_matrix_long = np.zeros((num_images*num_grids*num_patches,100))\n",
    "    z=0\n",
    "    for i in range(num_images):\n",
    "        for j in range(num_grids):\n",
    "            for k in range(num_patches):\n",
    "                data_matrix_long[z,:] = data[i][j][k]\n",
    "                z=z+1\n",
    "    #Finding the main 50 clusters\n",
    "    data_km_long = kmeans.predict(data_matrix_long)\n",
    "    data_50clusters= np.zeros((num_images,num_grids,num_patches))\n",
    "    z=0\n",
    "    for i in range(num_images):\n",
    "        for j in range(num_grids):\n",
    "            for k in range(num_patches):\n",
    "                data_50clusters[i,j,k] = data_km_long[z]\n",
    "                z=z+1\n",
    "    data_2500clusters= [[['000_000' for i in range(num_patches)] for j in range(num_grids)] for k in range(num_images)]\n",
    "    subcluster_data_fit = np.zeros((1,100))\n",
    "    z=1\n",
    "    #Finding the subclusters of each patch\n",
    "    for i in range(num_images):\n",
    "        for j in range(num_grids):\n",
    "            for k in range(num_patches):\n",
    "                cluster = data_50clusters[i,j,k]\n",
    "                subcluster_data_fit[0,:] = data[i][j][k]\n",
    "                fitted_centre=cluster_dict[str(int(cluster))].predict(subcluster_data_fit)\n",
    "                text=str(int(cluster))+'_'+str(fitted_centre[0])\n",
    "                data_2500clusters[i][j][k]= text\n",
    "                if z%10000==0 and z>=10000:\n",
    "                    print(str(z*100/(num_images*num_grids*num_patches))+'% done')\n",
    "                z=z+1\n",
    "    return(data_2500clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% done\n",
      "1% done\n",
      "2% done\n",
      "2% done\n",
      "3% done\n",
      "4% done\n",
      "4% done\n",
      "5% done\n",
      "6% done\n",
      "6% done\n",
      "7% done\n",
      "8% done\n",
      "9% done\n",
      "9% done\n",
      "10% done\n",
      "11% done\n",
      "11% done\n",
      "12% done\n",
      "13% done\n",
      "13% done\n",
      "14% done\n",
      "15% done\n",
      "15% done\n",
      "16% done\n",
      "17% done\n",
      "18% done\n",
      "18% done\n",
      "19% done\n",
      "20% done\n",
      "20% done\n",
      "21% done\n",
      "22% done\n",
      "22% done\n",
      "23% done\n",
      "24% done\n",
      "25% done\n",
      "25% done\n",
      "26% done\n",
      "27% done\n",
      "27% done\n",
      "28% done\n",
      "29% done\n",
      "29% done\n",
      "30% done\n",
      "31% done\n",
      "31% done\n",
      "32% done\n",
      "33% done\n",
      "34% done\n",
      "34% done\n",
      "35% done\n",
      "36% done\n",
      "36% done\n",
      "37% done\n",
      "38% done\n",
      "38% done\n",
      "39% done\n",
      "40% done\n",
      "40% done\n",
      "41% done\n",
      "42% done\n",
      "43% done\n",
      "43% done\n",
      "44% done\n",
      "45% done\n",
      "45% done\n",
      "46% done\n",
      "47% done\n",
      "47% done\n",
      "48% done\n",
      "49% done\n",
      "50% done\n",
      "50% done\n",
      "51% done\n",
      "52% done\n",
      "52% done\n",
      "53% done\n",
      "54% done\n",
      "54% done\n",
      "55% done\n",
      "56% done\n",
      "56% done\n",
      "57% done\n",
      "58% done\n",
      "59% done\n",
      "59% done\n",
      "60% done\n",
      "61% done\n",
      "61% done\n",
      "62% done\n",
      "63% done\n",
      "63% done\n",
      "64% done\n",
      "65% done\n",
      "65% done\n",
      "66% done\n",
      "67% done\n",
      "68% done\n",
      "68% done\n",
      "69% done\n",
      "70% done\n",
      "70% done\n",
      "71% done\n",
      "72% done\n",
      "72% done\n",
      "73% done\n",
      "74% done\n",
      "75% done\n",
      "75% done\n",
      "76% done\n",
      "77% done\n",
      "77% done\n",
      "78% done\n",
      "79% done\n",
      "79% done\n",
      "80% done\n",
      "81% done\n",
      "81% done\n",
      "82% done\n",
      "83% done\n",
      "84% done\n",
      "84% done\n",
      "85% done\n",
      "86% done\n",
      "86% done\n",
      "87% done\n",
      "88% done\n",
      "88% done\n",
      "89% done\n",
      "90% done\n",
      "90% done\n",
      "91% done\n",
      "92% done\n",
      "93% done\n",
      "93% done\n",
      "94% done\n",
      "95% done\n",
      "95% done\n",
      "96% done\n",
      "97% done\n",
      "97% done\n",
      "98% done\n",
      "99% done\n",
      "100% done\n"
     ]
    }
   ],
   "source": [
    "test_2500clusters = finding_cluster(testing_patches,10000,16,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0_0', '0_1', '0_10', ..., '9_7', '9_8', '9_9'], dtype='|S5')"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_2500clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_patch_creation(data,num_images=10000,num_grids=16,num_patches=9):\n",
    "    colnames=['image_num']\n",
    "    for i in range(50):\n",
    "        for j in range(50):\n",
    "            colnames.append(str(i)+'_'+str(j))\n",
    "    df=np.zeros((num_images,2501))\n",
    "    hist_patches = pd.DataFrame(df,columns = colnames)\n",
    "    hist_patches['image_num']=range(num_images)\n",
    "    z=1\n",
    "    for i in range(num_images):\n",
    "        for j in range(16):\n",
    "            for k in range(9):\n",
    "                hist_patches.loc[i,data[i][j][k]]+=1\n",
    "                if z%10000==0 and z>=10000:\n",
    "                    print(str(z*100/(num_images*num_grids*num_patches))+'% done')\n",
    "                z=z+1\n",
    "    return(hist_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% done\n",
      "1% done\n",
      "2% done\n",
      "2% done\n",
      "3% done\n",
      "4% done\n",
      "4% done\n",
      "5% done\n",
      "6% done\n",
      "6% done\n",
      "7% done\n",
      "8% done\n",
      "9% done\n",
      "9% done\n",
      "10% done\n",
      "11% done\n",
      "11% done\n",
      "12% done\n",
      "13% done\n",
      "13% done\n",
      "14% done\n",
      "15% done\n",
      "15% done\n",
      "16% done\n",
      "17% done\n",
      "18% done\n",
      "18% done\n",
      "19% done\n",
      "20% done\n",
      "20% done\n",
      "21% done\n",
      "22% done\n",
      "22% done\n",
      "23% done\n",
      "24% done\n",
      "25% done\n",
      "25% done\n",
      "26% done\n",
      "27% done\n",
      "27% done\n",
      "28% done\n",
      "29% done\n",
      "29% done\n",
      "30% done\n",
      "31% done\n",
      "31% done\n",
      "32% done\n",
      "33% done\n",
      "34% done\n",
      "34% done\n",
      "35% done\n",
      "36% done\n",
      "36% done\n",
      "37% done\n",
      "38% done\n",
      "38% done\n",
      "39% done\n",
      "40% done\n",
      "40% done\n",
      "41% done\n",
      "42% done\n",
      "43% done\n",
      "43% done\n",
      "44% done\n",
      "45% done\n",
      "45% done\n",
      "46% done\n",
      "47% done\n",
      "47% done\n",
      "48% done\n",
      "49% done\n",
      "50% done\n",
      "50% done\n",
      "51% done\n",
      "52% done\n",
      "52% done\n",
      "53% done\n",
      "54% done\n",
      "54% done\n",
      "55% done\n",
      "56% done\n",
      "56% done\n",
      "57% done\n",
      "58% done\n",
      "59% done\n",
      "59% done\n",
      "60% done\n",
      "61% done\n",
      "61% done\n",
      "62% done\n",
      "63% done\n",
      "63% done\n",
      "64% done\n",
      "65% done\n",
      "65% done\n",
      "66% done\n",
      "67% done\n",
      "68% done\n",
      "68% done\n",
      "69% done\n",
      "70% done\n",
      "70% done\n",
      "71% done\n",
      "72% done\n",
      "72% done\n",
      "73% done\n",
      "74% done\n",
      "75% done\n",
      "75% done\n",
      "76% done\n",
      "77% done\n",
      "77% done\n",
      "78% done\n",
      "79% done\n",
      "79% done\n",
      "80% done\n",
      "81% done\n",
      "81% done\n",
      "82% done\n",
      "83% done\n",
      "84% done\n",
      "84% done\n",
      "85% done\n",
      "86% done\n",
      "86% done\n",
      "87% done\n",
      "88% done\n",
      "88% done\n",
      "89% done\n",
      "90% done\n",
      "90% done\n",
      "91% done\n",
      "92% done\n",
      "93% done\n",
      "93% done\n",
      "94% done\n",
      "95% done\n",
      "95% done\n",
      "96% done\n",
      "97% done\n",
      "97% done\n",
      "98% done\n",
      "99% done\n",
      "100% done\n"
     ]
    }
   ],
   "source": [
    "test_hist_patches=histogram_patch_creation(test_2500clusters,10000,16,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1% done\n",
      "2% done\n",
      "3% done\n",
      "4% done\n",
      "5% done\n",
      "6% done\n",
      "8% done\n",
      "9% done\n",
      "10% done\n",
      "11% done\n",
      "12% done\n",
      "13% done\n",
      "15% done\n",
      "16% done\n",
      "17% done\n",
      "18% done\n",
      "19% done\n",
      "20% done\n",
      "21% done\n",
      "23% done\n",
      "24% done\n",
      "25% done\n",
      "26% done\n",
      "27% done\n",
      "28% done\n",
      "30% done\n",
      "31% done\n",
      "32% done\n",
      "33% done\n",
      "34% done\n",
      "35% done\n",
      "37% done\n",
      "38% done\n",
      "39% done\n",
      "40% done\n",
      "41% done\n",
      "42% done\n",
      "43% done\n",
      "45% done\n",
      "46% done\n",
      "47% done\n",
      "48% done\n",
      "49% done\n",
      "50% done\n",
      "52% done\n",
      "53% done\n",
      "54% done\n",
      "55% done\n",
      "56% done\n",
      "57% done\n",
      "59% done\n",
      "60% done\n",
      "61% done\n",
      "62% done\n",
      "63% done\n",
      "64% done\n",
      "65% done\n",
      "67% done\n",
      "68% done\n",
      "69% done\n",
      "70% done\n",
      "71% done\n",
      "72% done\n",
      "74% done\n",
      "75% done\n",
      "76% done\n",
      "77% done\n",
      "78% done\n",
      "79% done\n",
      "81% done\n",
      "82% done\n",
      "83% done\n",
      "84% done\n",
      "85% done\n",
      "86% done\n",
      "87% done\n",
      "89% done\n",
      "90% done\n",
      "91% done\n",
      "92% done\n",
      "93% done\n",
      "94% done\n",
      "96% done\n",
      "97% done\n",
      "98% done\n",
      "99% done\n"
     ]
    }
   ],
   "source": [
    "train_2500clusters = finding_cluster(training_patches, 6000, 16, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1% done\n",
      "2% done\n",
      "3% done\n",
      "4% done\n",
      "5% done\n",
      "6% done\n",
      "8% done\n",
      "9% done\n",
      "10% done\n",
      "11% done\n",
      "12% done\n",
      "13% done\n",
      "15% done\n",
      "16% done\n",
      "17% done\n",
      "18% done\n",
      "19% done\n",
      "20% done\n",
      "21% done\n",
      "23% done\n",
      "24% done\n",
      "25% done\n",
      "26% done\n",
      "27% done\n",
      "28% done\n",
      "30% done\n",
      "31% done\n",
      "32% done\n",
      "33% done\n",
      "34% done\n",
      "35% done\n",
      "37% done\n",
      "38% done\n",
      "39% done\n",
      "40% done\n",
      "41% done\n",
      "42% done\n",
      "43% done\n",
      "45% done\n",
      "46% done\n",
      "47% done\n",
      "48% done\n",
      "49% done\n",
      "50% done\n",
      "52% done\n",
      "53% done\n",
      "54% done\n",
      "55% done\n",
      "56% done\n",
      "57% done\n",
      "59% done\n",
      "60% done\n",
      "61% done\n",
      "62% done\n",
      "63% done\n",
      "64% done\n",
      "65% done\n",
      "67% done\n",
      "68% done\n",
      "69% done\n",
      "70% done\n",
      "71% done\n",
      "72% done\n",
      "74% done\n",
      "75% done\n",
      "76% done\n",
      "77% done\n",
      "78% done\n",
      "79% done\n",
      "81% done\n",
      "82% done\n",
      "83% done\n",
      "84% done\n",
      "85% done\n",
      "86% done\n",
      "87% done\n",
      "89% done\n",
      "90% done\n",
      "91% done\n",
      "92% done\n",
      "93% done\n",
      "94% done\n",
      "96% done\n",
      "97% done\n",
      "98% done\n",
      "99% done\n"
     ]
    }
   ],
   "source": [
    "train_hist_patches=histogram_patch_creation(train_2500clusters,6000,16,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(num_trees, depth, train_, test_, train_labels_):\n",
    "    model = rfc(n_estimators=num_trees, max_depth=depth)\n",
    "    model.fit(train_, train_labels_)\n",
    "    train_res = model.predict(train_)\n",
    "    test_res = model.predict(test_)\n",
    "    return train_res, test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(predictions, target):\n",
    "    correct = 0\n",
    "    for pred, actual in zip(predictions, target):\n",
    "        if pred == actual:\n",
    "            correct += 1\n",
    "    return correct / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy training: ', 0)\n",
      "('accuracy testing: ', 0)\n"
     ]
    }
   ],
   "source": [
    "train_res, test_res = decision_tree(20, 16, train_hist_patches, test_hist_patches, training_labels)\n",
    "print(\"accuracy training: \", cal_accuracy(train_res, training_labels))\n",
    "print(\"accuracy testing: \", cal_accuracy(test_res, testing_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 3, ..., 7, 9, 7])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "rf = RandomForestClassifier(n_estimators=100, oob_score=True).fit(train_hist_patches,training_labels)\n",
    "test_y_pred = rf.predict(test_hist_patches)\n",
    "train_y_pred = rf.predict(train_hist_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.79"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(testing_labels,test_y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(training_labels,train_y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
